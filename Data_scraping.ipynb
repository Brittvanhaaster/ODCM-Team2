{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341cbeba",
   "metadata": {},
   "source": [
    "This code scrapes the yearly ride wait information, specifically:\n",
    "- average wait time per ride\n",
    "- maximum wait time per ride\n",
    "- uptime per ride\n",
    "\n",
    "we use the same code for 3 years:\n",
    "PARK_ID = 160\n",
    "START, END = \"2025-01-01\", \"2025-11-11\"   # pas aan\n",
    "OUT = \"efteling_rides2025-11-11.csv\"\n",
    "\n",
    "PARK_ID = 160\n",
    "START, END = \"2024-01-01\", \"2024-12-31\"   # pas aan\n",
    "OUT = \"efteling_rides2024.csv\"\n",
    "\n",
    "PARK_ID = 160\n",
    "START, END = \"2023-01-01\", \"2023-12-31\"   # pas aan\n",
    "OUT = \"efteling_rides2023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6eaaad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Klaar: efteling_rides2025-11-11.csv\n"
     ]
    }
   ],
   "source": [
    "# tiny_queue_times.py\n",
    "import requests, pandas as pd, re\n",
    "from io import StringIO\n",
    "\n",
    "PARK_ID = 160\n",
    "START, END = \"2025-01-01\", \"2025-11-11\"   # pas aan\n",
    "OUT = \"efteling_rides2025-11-11.csv\"\n",
    "\n",
    "num = lambda s: (s.astype(str).str.replace(\",\", \".\", regex=False)\n",
    "                   .str.extract(r\"([\\d.]+)\")[0].astype(float))\n",
    "\n",
    "rows = []\n",
    "for d in pd.date_range(START, END):\n",
    "    url = f\"https://queue-times.com/parks/{PARK_ID}/calendar/{d:%Y/%m/%d}\"\n",
    "    html = requests.get(url, headers={\"User-Agent\":\"Mozilla/5.0\"}).text\n",
    "    tables = pd.read_html(StringIO(html))\n",
    "\n",
    "    avg = mx = up = None\n",
    "    for t in tables:\n",
    "        cols = [str(c).casefold() for c in t.columns]\n",
    "        if not cols or \"ride\" not in cols[0]: \n",
    "            continue\n",
    "        if len(cols) > 1 and \"queue\" in cols[1]:\n",
    "            if \"average\" in cols[1]:\n",
    "                avg = t.rename(columns={t.columns[0]:\"ride\", t.columns[1]:\"avg_queue_min\"})[[\"ride\",\"avg_queue_min\"]]\n",
    "                avg[\"avg_queue_min\"] = num(avg[\"avg_queue_min\"])\n",
    "            elif \"maximum\" in cols[1] or \"max\" in cols[1]:\n",
    "                mx  = t.rename(columns={t.columns[0]:\"ride\", t.columns[1]:\"max_queue_min\"})[[\"ride\",\"max_queue_min\"]]\n",
    "                mx[\"max_queue_min\"] = num(mx[\"max_queue_min\"])\n",
    "        if len(cols) > 1 and \"uptime\" in cols[1]:\n",
    "            up  = t.rename(columns={t.columns[0]:\"ride\", t.columns[1]:\"uptime_pct\"})[[\"ride\",\"uptime_pct\"]]\n",
    "            up[\"uptime_pct\"] = num(up[\"uptime_pct\"])\n",
    "\n",
    "    # merge per datum\n",
    "    df = None\n",
    "    for piece in (avg, mx, up):\n",
    "        if piece is not None:\n",
    "            df = piece if df is None else df.merge(piece, on=\"ride\", how=\"outer\")\n",
    "    if df is not None and not df.empty:\n",
    "        df.insert(0, \"date\", d.date().isoformat())\n",
    "        df.insert(1, \"park_id\", PARK_ID)\n",
    "        rows.append(df)\n",
    "\n",
    "# alles wegschrijven\n",
    "pd.concat(rows, ignore_index=True).to_csv(OUT, index=False)\n",
    "print(f\"âœ… Klaar: {OUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453967b",
   "metadata": {},
   "source": [
    "Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60e8c2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File merged and named: efteling_rides_all.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# lijst van jouw bestanden\n",
    "files = [\n",
    "    \"efteling_rides2023.csv\",\n",
    "    \"efteling_rides2024.csv\",\n",
    "    \"efteling_rides2025-11-11.csv\"\n",
    "]\n",
    "\n",
    "# inlezen en samenvoegen\n",
    "dataframes = [pd.read_csv(f) for f in files]\n",
    "all_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# sorteren op datum (optioneel)\n",
    "all_data = all_data.sort_values(\"date\")\n",
    "\n",
    "# opslaan als Ã©Ã©n bestand\n",
    "all_data.to_csv(\"efteling_rides_all.csv\", index=False)\n",
    "\n",
    "print(\"âœ… File merged and named: efteling_rides_all.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d516f7a",
   "metadata": {},
   "source": [
    "we use the same code for 3 years:\n",
    "PARK_ID = 160\n",
    "START, END = \"2025-01-01\", \"2025-11-11\"  \n",
    "OUT = \"efteling_meta_2025-11-11.csv\"\n",
    "\n",
    "PARK_ID = 160\n",
    "START, END = \"2024-01-01\", \"2024-12-31\"   \n",
    "OUT = \"efteling_meta_2024.csv\"\n",
    "\n",
    "PARK_ID = 160\n",
    "START, END = \"2023-01-01\", \"2023-12-31\"\n",
    "OUT = \"efteling_meta_2023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e0f8a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 2023-01-01 -> row written\n",
      "[OK] 2023-01-02 -> row written\n",
      "[OK] 2023-01-03 -> row written\n",
      "[OK] 2023-01-04 -> row written\n",
      "[OK] 2023-01-05 -> row written\n",
      "[OK] 2023-01-06 -> row written\n",
      "[OK] 2023-01-07 -> row written\n",
      "[OK] 2023-01-08 -> row written\n",
      "[OK] 2023-01-09 -> row written\n",
      "[OK] 2023-01-10 -> row written\n",
      "[OK] 2023-01-11 -> row written\n",
      "[OK] 2023-01-12 -> row written\n",
      "[OK] 2023-01-13 -> row written\n",
      "[OK] 2023-01-14 -> row written\n",
      "[OK] 2023-01-15 -> row written\n",
      "[OK] 2023-01-16 -> row written\n",
      "[OK] 2023-01-17 -> row written\n",
      "[OK] 2023-01-18 -> row written\n",
      "[OK] 2023-01-19 -> row written\n",
      "[OK] 2023-01-20 -> row written\n",
      "[OK] 2023-01-21 -> row written\n",
      "[OK] 2023-01-22 -> row written\n",
      "[OK] 2023-01-23 -> row written\n",
      "[OK] 2023-01-24 -> row written\n",
      "[OK] 2023-01-25 -> row written\n",
      "[OK] 2023-01-26 -> row written\n",
      "[OK] 2023-01-27 -> row written\n",
      "[OK] 2023-01-28 -> row written\n",
      "[OK] 2023-01-29 -> row written\n",
      "[OK] 2023-01-30 -> row written\n",
      "[OK] 2023-01-31 -> row written\n",
      "[OK] 2023-02-01 -> row written\n",
      "[OK] 2023-02-02 -> row written\n",
      "[OK] 2023-02-03 -> row written\n",
      "[OK] 2023-02-04 -> row written\n",
      "[OK] 2023-02-05 -> row written\n",
      "[OK] 2023-02-06 -> row written\n",
      "[OK] 2023-02-07 -> row written\n",
      "[OK] 2023-02-08 -> row written\n",
      "[OK] 2023-02-09 -> row written\n",
      "[OK] 2023-02-10 -> row written\n",
      "[OK] 2023-02-11 -> row written\n",
      "[OK] 2023-02-12 -> row written\n",
      "[OK] 2023-02-13 -> row written\n",
      "[OK] 2023-02-14 -> row written\n",
      "[OK] 2023-02-15 -> row written\n",
      "[OK] 2023-02-16 -> row written\n",
      "[OK] 2023-02-17 -> row written\n",
      "[OK] 2023-02-18 -> row written\n",
      "[OK] 2023-02-19 -> row written\n",
      "[OK] 2023-02-20 -> row written\n",
      "[OK] 2023-02-21 -> row written\n",
      "[OK] 2023-02-22 -> row written\n",
      "[OK] 2023-02-23 -> row written\n",
      "[OK] 2023-02-24 -> row written\n",
      "[OK] 2023-02-25 -> row written\n",
      "[OK] 2023-02-26 -> row written\n",
      "[OK] 2023-02-27 -> row written\n",
      "[OK] 2023-02-28 -> row written\n",
      "[OK] 2023-03-01 -> row written\n",
      "[OK] 2023-03-02 -> row written\n",
      "[OK] 2023-03-03 -> row written\n",
      "[OK] 2023-03-04 -> row written\n",
      "[OK] 2023-03-05 -> row written\n",
      "[OK] 2023-03-06 -> row written\n",
      "[OK] 2023-03-07 -> row written\n",
      "[OK] 2023-03-08 -> row written\n",
      "[OK] 2023-03-09 -> row written\n",
      "[OK] 2023-03-10 -> row written\n",
      "[OK] 2023-03-11 -> row written\n",
      "[OK] 2023-03-12 -> row written\n",
      "[OK] 2023-03-13 -> row written\n",
      "[OK] 2023-03-14 -> row written\n",
      "[OK] 2023-03-15 -> row written\n",
      "[OK] 2023-03-16 -> row written\n",
      "[OK] 2023-03-17 -> row written\n",
      "[OK] 2023-03-18 -> row written\n",
      "[OK] 2023-03-19 -> row written\n",
      "[OK] 2023-03-20 -> row written\n",
      "[OK] 2023-03-21 -> row written\n",
      "[OK] 2023-03-22 -> row written\n",
      "[OK] 2023-03-23 -> row written\n",
      "[OK] 2023-03-24 -> row written\n",
      "[OK] 2023-03-25 -> row written\n",
      "[OK] 2023-03-26 -> row written\n",
      "[OK] 2023-03-27 -> row written\n",
      "[OK] 2023-03-28 -> row written\n",
      "[OK] 2023-03-29 -> row written\n",
      "[OK] 2023-03-30 -> row written\n",
      "[OK] 2023-03-31 -> row written\n",
      "[OK] 2023-04-01 -> row written\n",
      "[OK] 2023-04-02 -> row written\n",
      "[OK] 2023-04-03 -> row written\n",
      "[OK] 2023-04-04 -> row written\n",
      "[OK] 2023-04-05 -> row written\n",
      "[OK] 2023-04-06 -> row written\n",
      "[OK] 2023-04-07 -> row written\n",
      "[OK] 2023-04-08 -> row written\n",
      "[OK] 2023-04-09 -> row written\n",
      "[OK] 2023-04-10 -> row written\n",
      "[OK] 2023-04-11 -> row written\n",
      "[OK] 2023-04-12 -> row written\n",
      "[OK] 2023-04-13 -> row written\n",
      "[OK] 2023-04-14 -> row written\n",
      "[OK] 2023-04-15 -> row written\n",
      "[OK] 2023-04-16 -> row written\n",
      "[OK] 2023-04-17 -> row written\n",
      "[OK] 2023-04-18 -> row written\n",
      "[OK] 2023-04-19 -> row written\n",
      "[OK] 2023-04-20 -> row written\n",
      "[OK] 2023-04-21 -> row written\n",
      "[OK] 2023-04-22 -> row written\n",
      "[OK] 2023-04-23 -> row written\n",
      "[OK] 2023-04-24 -> row written\n",
      "[OK] 2023-04-25 -> row written\n",
      "[OK] 2023-04-26 -> row written\n",
      "[OK] 2023-04-27 -> row written\n",
      "[OK] 2023-04-28 -> row written\n",
      "[OK] 2023-04-29 -> row written\n",
      "[OK] 2023-04-30 -> row written\n",
      "[OK] 2023-05-01 -> row written\n",
      "[OK] 2023-05-02 -> row written\n",
      "[OK] 2023-05-03 -> row written\n",
      "[OK] 2023-05-04 -> row written\n",
      "[OK] 2023-05-05 -> row written\n",
      "[OK] 2023-05-06 -> row written\n",
      "[OK] 2023-05-07 -> row written\n",
      "[OK] 2023-05-08 -> row written\n",
      "[OK] 2023-05-09 -> row written\n",
      "[OK] 2023-05-10 -> row written\n",
      "[OK] 2023-05-11 -> row written\n",
      "[OK] 2023-05-12 -> row written\n",
      "[OK] 2023-05-13 -> row written\n",
      "[OK] 2023-05-14 -> row written\n",
      "[OK] 2023-05-15 -> row written\n",
      "[OK] 2023-05-16 -> row written\n",
      "[OK] 2023-05-17 -> row written\n",
      "[OK] 2023-05-18 -> row written\n",
      "[OK] 2023-05-19 -> row written\n",
      "[OK] 2023-05-20 -> row written\n",
      "[OK] 2023-05-21 -> row written\n",
      "[OK] 2023-05-22 -> row written\n",
      "[OK] 2023-05-23 -> row written\n",
      "[OK] 2023-05-24 -> row written\n",
      "[OK] 2023-05-25 -> row written\n",
      "[OK] 2023-05-26 -> row written\n",
      "[OK] 2023-05-27 -> row written\n",
      "[OK] 2023-05-28 -> row written\n",
      "[OK] 2023-05-29 -> row written\n",
      "[OK] 2023-05-30 -> row written\n",
      "[OK] 2023-05-31 -> row written\n",
      "[OK] 2023-06-01 -> row written\n",
      "[OK] 2023-06-02 -> row written\n",
      "[OK] 2023-06-03 -> row written\n",
      "[OK] 2023-06-04 -> row written\n",
      "[OK] 2023-06-05 -> row written\n",
      "[OK] 2023-06-06 -> row written\n",
      "[OK] 2023-06-07 -> row written\n",
      "[OK] 2023-06-08 -> row written\n",
      "[OK] 2023-06-09 -> row written\n",
      "[OK] 2023-06-10 -> row written\n",
      "[OK] 2023-06-11 -> row written\n",
      "[OK] 2023-06-12 -> row written\n",
      "[OK] 2023-06-13 -> row written\n",
      "[OK] 2023-06-14 -> row written\n",
      "[OK] 2023-06-15 -> row written\n",
      "[OK] 2023-06-16 -> row written\n",
      "[OK] 2023-06-17 -> row written\n",
      "[OK] 2023-06-18 -> row written\n",
      "[OK] 2023-06-19 -> row written\n",
      "[OK] 2023-06-20 -> row written\n",
      "[OK] 2023-06-21 -> row written\n",
      "[OK] 2023-06-22 -> row written\n",
      "[OK] 2023-06-23 -> row written\n",
      "[OK] 2023-06-24 -> row written\n",
      "[OK] 2023-06-25 -> row written\n",
      "[OK] 2023-06-26 -> row written\n",
      "[OK] 2023-06-27 -> row written\n",
      "[OK] 2023-06-28 -> row written\n",
      "[OK] 2023-06-29 -> row written\n",
      "[OK] 2023-06-30 -> row written\n",
      "[OK] 2023-07-01 -> row written\n",
      "[OK] 2023-07-02 -> row written\n",
      "[OK] 2023-07-03 -> row written\n",
      "[OK] 2023-07-04 -> row written\n",
      "[OK] 2023-07-05 -> row written\n",
      "[OK] 2023-07-06 -> row written\n",
      "[OK] 2023-07-07 -> row written\n",
      "[OK] 2023-07-08 -> row written\n",
      "[OK] 2023-07-09 -> row written\n",
      "[OK] 2023-07-10 -> row written\n",
      "[OK] 2023-07-11 -> row written\n",
      "[OK] 2023-07-12 -> row written\n",
      "[OK] 2023-07-13 -> row written\n",
      "[OK] 2023-07-14 -> row written\n",
      "[OK] 2023-07-15 -> row written\n",
      "[OK] 2023-07-16 -> row written\n",
      "[OK] 2023-07-17 -> row written\n",
      "[OK] 2023-07-18 -> row written\n",
      "[OK] 2023-07-19 -> row written\n",
      "[OK] 2023-07-20 -> row written\n",
      "[OK] 2023-07-21 -> row written\n",
      "[OK] 2023-07-22 -> row written\n",
      "[OK] 2023-07-23 -> row written\n",
      "[OK] 2023-07-24 -> row written\n",
      "[OK] 2023-07-25 -> row written\n",
      "[OK] 2023-07-26 -> row written\n",
      "[OK] 2023-07-27 -> row written\n",
      "[OK] 2023-07-28 -> row written\n",
      "[OK] 2023-07-29 -> row written\n",
      "[OK] 2023-07-30 -> row written\n",
      "[OK] 2023-07-31 -> row written\n",
      "[OK] 2023-08-01 -> row written\n",
      "[OK] 2023-08-02 -> row written\n",
      "[OK] 2023-08-03 -> row written\n",
      "[OK] 2023-08-04 -> row written\n",
      "[OK] 2023-08-05 -> row written\n",
      "[OK] 2023-08-06 -> row written\n",
      "[OK] 2023-08-07 -> row written\n",
      "[OK] 2023-08-08 -> row written\n",
      "[OK] 2023-08-09 -> row written\n",
      "[OK] 2023-08-10 -> row written\n",
      "[OK] 2023-08-11 -> row written\n",
      "[OK] 2023-08-12 -> row written\n",
      "[OK] 2023-08-13 -> row written\n",
      "[OK] 2023-08-14 -> row written\n",
      "[OK] 2023-08-15 -> row written\n",
      "[OK] 2023-08-16 -> row written\n",
      "[OK] 2023-08-17 -> row written\n",
      "[OK] 2023-08-18 -> row written\n",
      "[OK] 2023-08-19 -> row written\n",
      "[OK] 2023-08-20 -> row written\n",
      "[OK] 2023-08-21 -> row written\n",
      "[OK] 2023-08-22 -> row written\n",
      "[OK] 2023-08-23 -> row written\n",
      "[OK] 2023-08-24 -> row written\n",
      "[OK] 2023-08-25 -> row written\n",
      "[OK] 2023-08-26 -> row written\n",
      "[OK] 2023-08-27 -> row written\n",
      "[OK] 2023-08-28 -> row written\n",
      "[OK] 2023-08-29 -> row written\n",
      "[OK] 2023-08-30 -> row written\n",
      "[OK] 2023-08-31 -> row written\n",
      "[OK] 2023-09-01 -> row written\n",
      "[OK] 2023-09-02 -> row written\n",
      "[OK] 2023-09-03 -> row written\n",
      "[OK] 2023-09-04 -> row written\n",
      "[OK] 2023-09-05 -> row written\n",
      "[OK] 2023-09-06 -> row written\n",
      "[OK] 2023-09-07 -> row written\n",
      "[OK] 2023-09-08 -> row written\n",
      "[OK] 2023-09-09 -> row written\n",
      "[OK] 2023-09-10 -> row written\n",
      "[OK] 2023-09-11 -> row written\n",
      "[OK] 2023-09-12 -> row written\n",
      "[OK] 2023-09-13 -> row written\n",
      "[OK] 2023-09-14 -> row written\n",
      "[OK] 2023-09-15 -> row written\n",
      "[OK] 2023-09-16 -> row written\n",
      "[OK] 2023-09-17 -> row written\n",
      "[OK] 2023-09-18 -> row written\n",
      "[OK] 2023-09-19 -> row written\n",
      "[OK] 2023-09-20 -> row written\n",
      "[OK] 2023-09-21 -> row written\n",
      "[OK] 2023-09-22 -> row written\n",
      "[OK] 2023-09-23 -> row written\n",
      "[OK] 2023-09-24 -> row written\n",
      "[OK] 2023-09-25 -> row written\n",
      "[OK] 2023-09-26 -> row written\n",
      "[OK] 2023-09-27 -> row written\n",
      "[OK] 2023-09-28 -> row written\n",
      "[OK] 2023-09-29 -> row written\n",
      "[OK] 2023-09-30 -> row written\n",
      "[OK] 2023-10-01 -> row written\n",
      "[OK] 2023-10-02 -> row written\n",
      "[OK] 2023-10-03 -> row written\n",
      "[OK] 2023-10-04 -> row written\n",
      "[OK] 2023-10-05 -> row written\n",
      "[OK] 2023-10-06 -> row written\n",
      "[OK] 2023-10-07 -> row written\n",
      "[OK] 2023-10-08 -> row written\n",
      "[OK] 2023-10-09 -> row written\n",
      "[OK] 2023-10-10 -> row written\n",
      "[OK] 2023-10-11 -> row written\n",
      "[OK] 2023-10-12 -> row written\n",
      "[OK] 2023-10-13 -> row written\n",
      "[OK] 2023-10-14 -> row written\n",
      "[OK] 2023-10-15 -> row written\n",
      "[OK] 2023-10-16 -> row written\n",
      "[OK] 2023-10-17 -> row written\n",
      "[OK] 2023-10-18 -> row written\n",
      "[OK] 2023-10-19 -> row written\n",
      "[OK] 2023-10-20 -> row written\n",
      "[OK] 2023-10-21 -> row written\n",
      "[OK] 2023-10-22 -> row written\n",
      "[OK] 2023-10-23 -> row written\n",
      "[OK] 2023-10-24 -> row written\n",
      "[OK] 2023-10-25 -> row written\n",
      "[OK] 2023-10-26 -> row written\n",
      "[OK] 2023-10-27 -> row written\n",
      "[OK] 2023-10-28 -> row written\n",
      "[OK] 2023-10-29 -> row written\n",
      "[OK] 2023-10-30 -> row written\n",
      "[OK] 2023-10-31 -> row written\n",
      "[OK] 2023-11-01 -> row written\n",
      "[OK] 2023-11-02 -> row written\n",
      "[OK] 2023-11-03 -> row written\n",
      "[OK] 2023-11-04 -> row written\n",
      "[OK] 2023-11-05 -> row written\n",
      "[OK] 2023-11-06 -> row written\n",
      "[OK] 2023-11-07 -> row written\n",
      "[OK] 2023-11-08 -> row written\n",
      "[OK] 2023-11-09 -> row written\n",
      "[OK] 2023-11-10 -> row written\n",
      "[OK] 2023-11-11 -> row written\n",
      "[OK] 2023-11-12 -> row written\n",
      "[OK] 2023-11-13 -> row written\n",
      "[OK] 2023-11-14 -> row written\n",
      "[OK] 2023-11-15 -> row written\n",
      "[OK] 2023-11-16 -> row written\n",
      "[OK] 2023-11-17 -> row written\n",
      "[OK] 2023-11-18 -> row written\n",
      "[OK] 2023-11-19 -> row written\n",
      "[OK] 2023-11-20 -> row written\n",
      "[OK] 2023-11-21 -> row written\n",
      "[OK] 2023-11-22 -> row written\n",
      "[OK] 2023-11-23 -> row written\n",
      "[OK] 2023-11-24 -> row written\n",
      "[OK] 2023-11-25 -> row written\n",
      "[OK] 2023-11-26 -> row written\n",
      "[OK] 2023-11-27 -> row written\n",
      "[OK] 2023-11-28 -> row written\n",
      "[OK] 2023-11-29 -> row written\n",
      "[OK] 2023-11-30 -> row written\n",
      "[OK] 2023-12-01 -> row written\n",
      "[OK] 2023-12-02 -> row written\n",
      "[OK] 2023-12-03 -> row written\n",
      "[OK] 2023-12-04 -> row written\n",
      "[OK] 2023-12-05 -> row written\n",
      "[OK] 2023-12-06 -> row written\n",
      "[OK] 2023-12-07 -> row written\n",
      "[OK] 2023-12-08 -> row written\n",
      "[OK] 2023-12-09 -> row written\n",
      "[OK] 2023-12-10 -> row written\n",
      "[OK] 2023-12-11 -> row written\n",
      "[OK] 2023-12-12 -> row written\n",
      "[OK] 2023-12-13 -> row written\n",
      "[OK] 2023-12-14 -> row written\n",
      "[OK] 2023-12-15 -> row written\n",
      "[OK] 2023-12-16 -> row written\n",
      "[OK] 2023-12-17 -> row written\n",
      "[OK] 2023-12-18 -> row written\n",
      "[OK] 2023-12-19 -> row written\n",
      "[OK] 2023-12-20 -> row written\n",
      "[OK] 2023-12-21 -> row written\n",
      "[OK] 2023-12-22 -> row written\n",
      "[OK] 2023-12-23 -> row written\n",
      "[OK] 2023-12-24 -> row written\n",
      "[OK] 2023-12-25 -> row written\n",
      "[OK] 2023-12-26 -> row written\n",
      "[OK] 2023-12-27 -> row written\n",
      "[OK] 2023-12-28 -> row written\n",
      "[OK] 2023-12-29 -> row written\n",
      "[OK] 2023-12-30 -> row written\n",
      "[OK] 2023-12-31 -> row written\n",
      "\n",
      "âœ… Done. Wrote 365 rows to efteling_meta_2023.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from datetime import date, timedelta\n",
    "\n",
    "PARK_ID = 160\n",
    "START = \"2023-01-01\"   # change as needed (YYYY-MM-DD)\n",
    "END   = \"2023-12-31\"   # inclusive\n",
    "OUT_CSV = \"efteling_meta_2023.csv\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; EftelingMetaScraper/1.0)\"\n",
    "}\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    \"\"\"Yield date objects from start_date to end_date inclusive.\"\"\"\n",
    "    d = start_date\n",
    "    while d <= end_date:\n",
    "        yield d\n",
    "        d += timedelta(days=1)\n",
    "\n",
    "def to_float(text):\n",
    "    \"\"\"Extract first number from text and return as float (handles 12,3 or 12.3).\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    m = re.search(r\"[-+]?\\d+(?:[.,]\\d+)?\", text)\n",
    "    return float(m.group(0).replace(\",\", \".\")) if m else None\n",
    "\n",
    "def get_crowd_values(soup):\n",
    "    \"\"\"\n",
    "    Find both 'Crowd level' rows:\n",
    "      - one with a percentage (e.g. '13%')\n",
    "      - one with a label (e.g. 'Empty')\n",
    "    Returns (crowd_percent_str, crowd_label_str)\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    for block in soup.select(\"div.panel-block\"):\n",
    "        spans = block.find_all(\"span\")\n",
    "        if spans and spans[0].get_text(strip=True) == \"Crowd level\":\n",
    "            if len(spans) > 1:\n",
    "                values.append(spans[1].get_text(strip=True))\n",
    "    crowd_percent = next((v for v in values if \"%\" in v), None)\n",
    "    crowd_label = next((v for v in values if \"%\" not in v), None)\n",
    "    return crowd_percent, crowd_label\n",
    "\n",
    "def get_opening_hours(soup):\n",
    "    \"\"\"Get the first tab text like 'ðŸŽ„ 10:00-20:00'.\"\"\"\n",
    "    link = soup.select_one(\"#tabs a\")\n",
    "    return link.get_text(strip=True) if link else None\n",
    "\n",
    "def get_panel_forecast_actual(soup, title_contains):\n",
    "    \"\"\"\n",
    "    In the panel whose <h2> contains title_contains, read:\n",
    "      'Forecast average' and 'Actual average'\n",
    "    Returns (forecast_float, actual_float)\n",
    "    \"\"\"\n",
    "    title_contains = title_contains.lower()\n",
    "    for h2 in soup.select(\"div.panel .panel-heading h2\"):\n",
    "        title = h2.get_text(strip=True).lower()\n",
    "        if title_contains in title:\n",
    "            panel = h2.find_parent(\"div\", class_=\"panel\")\n",
    "            if not panel:\n",
    "                break\n",
    "            forecast = actual = None\n",
    "            for block in panel.select(\"div.panel-block\"):\n",
    "                spans = block.find_all(\"span\")\n",
    "                if len(spans) >= 2:\n",
    "                    key = spans[0].get_text(strip=True).lower()\n",
    "                    val = spans[1].get_text(strip=True)\n",
    "                    if \"forecast average\" in key:\n",
    "                        forecast = to_float(val)\n",
    "                    elif \"actual average\" in key:\n",
    "                        actual = to_float(val)\n",
    "            return forecast, actual\n",
    "    return None, None\n",
    "\n",
    "def get_events(soup):\n",
    "    \"\"\"Return a semicolon-joined string of event names (if any).\"\"\"\n",
    "    for h2 in soup.select(\"div.panel .panel-heading h2\"):\n",
    "        if \"events\" in h2.get_text(strip=True).lower():\n",
    "            panel = h2.find_parent(\"div\", class_=\"panel\")\n",
    "            if not panel:\n",
    "                return None\n",
    "            names = []\n",
    "            for block in panel.select(\"div.panel-block\"):\n",
    "                span = block.find(\"span\")\n",
    "                if span:\n",
    "                    txt = span.get_text(strip=True)\n",
    "                    if txt:\n",
    "                        names.append(txt)\n",
    "            return \"; \".join(names) if names else None\n",
    "    return None\n",
    "\n",
    "def scrape_day(d):\n",
    "    \"\"\"Scrape one day and return a dict with all fields.\"\"\"\n",
    "    url = f\"https://queue-times.com/parks/{PARK_ID}/calendar/{d:%Y/%m/%d}\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=30)\n",
    "    if resp.status_code != 200:\n",
    "        return None  # page missing or failed\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # Basic info\n",
    "    date_title = soup.find(\"h1\", class_=\"title\")\n",
    "    date_text = date_title.get_text(strip=True) if date_title else d.isoformat()\n",
    "\n",
    "    # Fields you requested\n",
    "    crowd_pct, crowd_label = get_crowd_values(soup)\n",
    "    hours = get_opening_hours(soup)\n",
    "\n",
    "    temp_fore, temp_actual = get_panel_forecast_actual(soup, \"Temperature\")\n",
    "    prec_fore, prec_actual = get_panel_forecast_actual(soup, \"Precipitation intensity\")\n",
    "    wind_fore, wind_actual = get_panel_forecast_actual(soup, \"Wind speed\")\n",
    "\n",
    "    events = get_events(soup)\n",
    "\n",
    "    return {\n",
    "        \"date\": d.isoformat(),\n",
    "        \"page_date_heading\": date_text,\n",
    "        \"park_id\": PARK_ID,\n",
    "        \"crowd_percent\": crowd_pct,        # string like \"13%\"\n",
    "        \"crowd_label\": crowd_label,        # e.g. \"Empty\"\n",
    "        \"temperature_forecast_c\": temp_fore,\n",
    "        \"temperature_actual_c\":   temp_actual,\n",
    "        \"intensity_forecast_mmph\": prec_fore,\n",
    "        \"intensity_actual_mmph\":   prec_actual,\n",
    "        \"wind_forecast_mps\": wind_fore,\n",
    "        \"wind_actual_mps\":   wind_actual,\n",
    "        \"opening_hours\": hours,            # e.g. \"ðŸŽ„ 10:00-20:00\"\n",
    "        \"events\": events                   # e.g. \"ðŸŽ„ Winter Efteling\"\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    start = date.fromisoformat(START)\n",
    "    end   = date.fromisoformat(END)\n",
    "\n",
    "    fieldnames = [\n",
    "        \"date\",\"page_date_heading\",\"park_id\",\n",
    "        \"crowd_percent\",\"crowd_label\",\n",
    "        \"temperature_forecast_c\",\"temperature_actual_c\",\n",
    "        \"intensity_forecast_mmph\",\"intensity_actual_mmph\",\n",
    "        \"wind_forecast_mps\",\"wind_actual_mps\",\n",
    "        \"opening_hours\",\"events\"\n",
    "    ]\n",
    "\n",
    "    rows_written = 0\n",
    "    with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for d in daterange(start, end):\n",
    "            try:\n",
    "                data = scrape_day(d)\n",
    "                if data:\n",
    "                    writer.writerow(data)\n",
    "                    rows_written += 1\n",
    "                    print(f\"[OK] {d} -> row written\")\n",
    "                else:\n",
    "                    print(f\"[SKIP] {d} -> page not found or error\")\n",
    "            except Exception as e:\n",
    "                print(f\"[ERR]  {d} -> {e}\")\n",
    "\n",
    "    print(f\"\\nâœ… Done. Wrote {rows_written} rows to {OUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce35990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File merged and named: efteling_metadata_all.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# lijst van jouw bestanden\n",
    "files = [\n",
    "    \"efteling_meta_2023.csv\",\n",
    "    \"efteling_meta_2024.csv\",\n",
    "    \"efteling_meta_2025-11-11.csv\"\n",
    "]\n",
    "\n",
    "# inlezen en samenvoegen\n",
    "dataframes = [pd.read_csv(f) for f in files]\n",
    "all_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# sorteren op datum (optioneel)\n",
    "all_data = all_data.sort_values(\"date\")\n",
    "\n",
    "# opslaan als Ã©Ã©n bestand\n",
    "all_data.to_csv(\"efteling_metadata_all.csv\", index=False)\n",
    "\n",
    "print(\"âœ… File merged and named: efteling_metadata_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
